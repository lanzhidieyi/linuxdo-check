"""
cron: 0 */6 * * *
new Env("Linux.Do ç­¾åˆ°")
"""

import os
import random
import time
import functools
import re
from loguru import logger
from DrissionPage import ChromiumOptions, Chromium
from tabulate import tabulate
from curl_cffi import requests
from bs4 import BeautifulSoup

# ----------------------------
# Retry Decorator
# ----------------------------
def retry_decorator(retries=3, min_delay=5, max_delay=10):
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == retries - 1:
                        logger.error(f"å‡½æ•° {func.__name__} æœ€ç»ˆæ‰§è¡Œå¤±è´¥: {str(e)}")
                    logger.warning(
                        f"å‡½æ•° {func.__name__} ç¬¬ {attempt + 1}/{retries} æ¬¡å°è¯•å¤±è´¥: {str(e)}"
                    )
                    if attempt < retries - 1:
                        sleep_s = random.uniform(min_delay, max_delay)
                        logger.info(
                            f"å°†åœ¨ {sleep_s:.2f}s åé‡è¯• ({min_delay}-{max_delay}s éšæœºå»¶è¿Ÿ)"
                        )
                        time.sleep(sleep_s)
            return None

        return wrapper

    return decorator


# ----------------------------
# Env & Config
# ----------------------------
os.environ.pop("DISPLAY", None)
os.environ.pop("DYLD_LIBRARY_PATH", None)

USERNAME = os.environ.get("LINUXDO_USERNAME") or os.environ.get("USERNAME")
PASSWORD = os.environ.get("LINUXDO_PASSWORD") or os.environ.get("PASSWORD")

BROWSE_ENABLED = os.environ.get("BROWSE_ENABLED", "true").strip().lower() not in [
    "false",
    "0",
    "off",
]

# ä½ è¦çš„ï¼šè‡³å°‘æµè§ˆ 5~10 â€œé¡µ/æ‰¹æ¬¡â€ è¯„è®ºï¼ˆé»˜è®¤ï¼‰
MIN_COMMENT_PAGES = int(os.environ.get("MIN_COMMENT_PAGES", "5"))
MAX_COMMENT_PAGES = int(os.environ.get("MAX_COMMENT_PAGES", "10"))

GOTIFY_URL = os.environ.get("GOTIFY_URL")
GOTIFY_TOKEN = os.environ.get("GOTIFY_TOKEN")
SC3_PUSH_KEY = os.environ.get("SC3_PUSH_KEY")
WXPUSH_URL = os.environ.get("WXPUSH_URL")
WXPUSH_TOKEN = os.environ.get("WXPUSH_TOKEN")

# è®¿é—®å…¥å£
LIST_URL = "https://linux.do/latest"
HOME_FOR_COOKIE = "https://linux.do/"
LOGIN_URL = "https://linux.do/login"
SESSION_URL = "https://linux.do/session"
CSRF_URL = "https://linux.do/session/csrf"


class LinuxDoBrowser:
    def __init__(self) -> None:
        from sys import platform

        if platform.startswith("linux"):
            platformIdentifier = "X11; Linux x86_64"
        elif platform == "darwin":
            platformIdentifier = "Macintosh; Intel Mac OS X 10_15_7"
        elif platform == "win32":
            platformIdentifier = "Windows NT 10.0; Win64; x64"
        else:
            platformIdentifier = "X11; Linux x86_64"

        co = (
            ChromiumOptions()
            .headless(True)
            .incognito(True)
            .set_argument("--no-sandbox")
        )
        co.set_user_agent(
            f"Mozilla/5.0 ({platformIdentifier}) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"
        )
        self.browser = Chromium(co)
        self.page = self.browser.new_tab()

        self.session = requests.Session()
        self.session.headers.update(
            {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
                "(KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36",
                "Accept": "application/json, text/javascript, */*; q=0.01",
                "Accept-Language": "zh-CN,zh;q=0.9",
            }
        )

    # ----------------------------
    # Headers
    # ----------------------------
    def _api_headers(self):
        return {
            "User-Agent": self.session.headers.get("User-Agent"),
            "Accept": "application/json, text/javascript, */*; q=0.01",
            "Accept-Language": "zh-CN,zh;q=0.9",
            "X-Requested-With": "XMLHttpRequest",
            "Referer": LOGIN_URL,
            "Origin": "https://linux.do",
        }

    def _html_headers(self):
        return {
            "User-Agent": self.session.headers.get("User-Agent"),
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
            "Accept-Language": "zh-CN,zh;q=0.9",
            "Referer": HOME_FOR_COOKIE,
        }

    # ----------------------------
    # CSRF + Login
    # ----------------------------
    def _get_csrf_token(self) -> str:
        r0 = self.session.get(
            HOME_FOR_COOKIE,
            headers=self._html_headers(),
            impersonate="chrome136",
            allow_redirects=True,
            timeout=30,
        )
        logger.info(
            f"HOME: status={r0.status_code} ct={r0.headers.get('content-type')} url={getattr(r0, 'url', None)}"
        )

        resp_csrf = self.session.get(
            CSRF_URL,
            headers=self._api_headers(),
            impersonate="chrome136",
            allow_redirects=True,
            timeout=30,
        )
        ct = (resp_csrf.headers.get("content-type") or "").lower()
        logger.info(
            f"CSRF: status={resp_csrf.status_code} ct={resp_csrf.headers.get('content-type')} url={getattr(resp_csrf, 'url', None)}"
        )

        if resp_csrf.status_code != 200 or "application/json" not in ct:
            head = (resp_csrf.text or "")[:200]
            raise RuntimeError(
                f"CSRF not JSON. status={resp_csrf.status_code}, ct={ct}, head={head}"
            )

        data = resp_csrf.json()
        csrf = data.get("csrf")
        if not csrf:
            raise RuntimeError(f"CSRF JSON missing token keys: {list(data.keys())}")
        return csrf

    def login(self):
        logger.info("å¼€å§‹ç™»å½•")
        logger.info("è·å– CSRF token...")

        try:
            csrf_token = self._get_csrf_token()
        except Exception as e:
            logger.error(f"è·å– CSRF å¤±è´¥ï¼š{e}")
            return False

        logger.info("æ­£åœ¨ç™»å½•...")

        headers = self._api_headers()
        headers.update(
            {
                "X-CSRF-Token": csrf_token,
                "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
            }
        )

        data = {
            "login": USERNAME,
            "password": PASSWORD,
            "timezone": "Asia/Shanghai",
        }

        try:
            resp_login = self.session.post(
                SESSION_URL,
                data=data,
                impersonate="chrome136",
                headers=headers,
                allow_redirects=True,
                timeout=30,
            )
            logger.info(
                f"LOGIN: status={resp_login.status_code} ct={resp_login.headers.get('content-type')} url={getattr(resp_login, 'url', None)}"
            )

            ct = (resp_login.headers.get("content-type") or "").lower()
            if "application/json" not in ct:
                logger.error(f"ç™»å½•è¿”å›ä¸æ˜¯ JSONï¼Œhead={resp_login.text[:200]}")
                return False

            response_json = resp_login.json()
            if response_json.get("error"):
                logger.error(f"ç™»å½•å¤±è´¥: {response_json.get('error')}")
                return False

            logger.info("ç™»å½•æˆåŠŸ!")
        except Exception as e:
            logger.error(f"ç™»å½•è¯·æ±‚å¼‚å¸¸: {e}")
            return False

        self.print_connect_info()

        # åŒæ­¥ Cookie åˆ° DrissionPage
        logger.info("åŒæ­¥ Cookie åˆ° DrissionPage...")
        cookies_dict = self.session.cookies.get_dict()
        dp_cookies = []
        for name, value in cookies_dict.items():
            dp_cookies.append(
                {"name": name, "value": value, "domain": ".linux.do", "path": "/"}
            )
        self.page.set.cookies(dp_cookies)

        logger.info("Cookie è®¾ç½®å®Œæˆï¼Œå¯¼èˆªè‡³ä¸»é¢˜åˆ—è¡¨é¡µ /latest ...")
        self.page.get(LIST_URL)

        # Discourse å‰ç«¯æ¸²æŸ“ï¼šæ›´ç¨³çš„ç­‰å¾…ç­–ç•¥
        try:
            self.page.wait.ele("@id=main-outlet", timeout=25)
        except Exception:
            logger.warning("æœªç­‰åˆ° main-outletï¼Œä½†ç»§ç»­å°è¯•æŸ¥æ‰¾ topic link")

        ok = self._wait_any_topic_link(timeout=35)
        if not ok:
            logger.warning("æœªç­‰åˆ°ä¸»é¢˜é“¾æ¥ a.raw-topic-linkï¼Œè¾“å‡ºé¡µé¢ä¿¡æ¯è¾…åŠ©å®šä½")
            logger.warning(f"url={self.page.url}")
            logger.warning((self.page.html or "")[:500])
            # requests å·²ç™»å½•æˆåŠŸï¼Œè¿™é‡Œä¸å¼ºè¡Œå¤±è´¥
            return True

        logger.info("ä¸»é¢˜åˆ—è¡¨å·²æ¸²æŸ“ï¼Œç™»å½•&é¡µé¢åŠ è½½å®Œæˆ")
        return True

    def _wait_any_topic_link(self, timeout=30) -> bool:
        """ç­‰å¾… Discourse ä¸»é¢˜æ ‡é¢˜é“¾æ¥å‡ºç°"""
        end = time.time() + timeout
        while time.time() < end:
            try:
                links = self.page.eles("css:a.raw-topic-link")
                if links and len(links) > 0:
                    return True
            except Exception:
                pass
            time.sleep(0.8)
        return False

    # ----------------------------
    # Topic load helpers (å…³é”®ï¼šè¯„è®º/å›å¤åŠ è½½)
    # ----------------------------
    def wait_topic_posts_ready(self, page, timeout=35) -> bool:
        """
        ç­‰å¾…è¯é¢˜é¡µçš„å¸–å­æµå‡ºç°ï¼Œå¹¶å°½é‡ç­‰åŠ è½½çŠ¶æ€ç»“æŸ
        """
        end = time.time() + timeout

        # ç­‰è‡³å°‘ä¸€ä¸ª post
        try:
            page.wait.ele("css:article.topic-post", timeout=min(20, timeout))
        except Exception:
            logger.warning("æœªç­‰åˆ° article.topic-postï¼ˆå¸–å­æµï¼‰ï¼Œå¯èƒ½ç»“æ„å˜æ›´æˆ–è¢«æ‹¦æˆª")
            return False

        # ç­‰ aria-busy / å¸¸è§ loading æ¶ˆå¤±
        while time.time() < end:
            try:
                busy = page.run_js("""
                    const ps = document.querySelector('#post-stream');
                    return ps && ps.getAttribute('aria-busy') === 'true';
                """)
                if busy:
                    time.sleep(0.4)
                    continue

                loading_visible = page.run_js("""
                    const sels = [
                      '.spinner', '.loading-container', '.loading', '.topic-loading',
                      '.composer-loading', '.discourse-spinner'
                    ];
                    return sels.some(sel => {
                      const el = document.querySelector(sel);
                      if (!el) return false;
                      const st = window.getComputedStyle(el);
                      return st && st.display !== 'none' && st.visibility !== 'hidden' && st.opacity !== '0';
                    });
                """)
                if loading_visible:
                    time.sleep(0.4)
                    continue

                # ç¨³å¦¥ï¼šå†ç­‰ä¸€ä¸‹
                time.sleep(random.uniform(1.2, 2.0))
                return True
            except Exception:
                time.sleep(0.5)

        logger.warning("ç­‰å¾…å¸–å­æµ ready è¶…æ—¶")
        return True  # ä¸ç¡¬å¤±è´¥ï¼Œé¿å…å½±å“åç»­

    def wait_topic_progress_stable(self, page, stable_seconds=2.5, timeout=25) -> bool:
        """
        ç­‰å³ä¾§æ—¶é—´è½´ï¼ˆä½ å›¾é‡Œè“ç‚¹æ‰€åœ¨åŒºåŸŸï¼‰ç¨³å®šï¼š
        åˆ¤å®šæ ‡å‡†ï¼š#topic-progress çš„ innerText åœ¨ stable_seconds å†…ä¸å†å˜åŒ–
        """
        end = time.time() + timeout
        last_text = None
        stable_start = None

        while time.time() < end:
            try:
                text = page.run_js("""
                    const el = document.querySelector('#topic-progress');
                    return el ? el.innerText.trim() : null;
                """)
                if not text:
                    time.sleep(0.4)
                    continue

                if text == last_text:
                    if stable_start is None:
                        stable_start = time.time()
                    elif time.time() - stable_start >= stable_seconds:
                        return True
                else:
                    last_text = text
                    stable_start = None

                time.sleep(0.4)
            except Exception:
                time.sleep(0.4)

        return False

    def _current_post_number(self, page) -> int:
        """ä»å³ä¾§æ—¶é—´è½´æå–å½“å‰æ¥¼å±‚å·ï¼Œå¦‚ '#2422' -> 2422ï¼›å–ä¸åˆ°è¿”å› 0"""
        try:
            s = page.run_js("""
                const el = document.querySelector('#topic-progress');
                return el ? el.innerText : '';
            """) or ""
            m = re.search(r"#(\\d+)", s)
            return int(m.group(1)) if m else 0
        except Exception:
            return 0

    def browse_replies_pages(self, page, min_pages=5, max_pages=10):
        """
        è‡³å°‘æµè§ˆ min_pages é¡µï¼Œæœ€å¤š max_pages é¡µï¼ˆæŒ‰â€œå³ä¾§æ¥¼å±‚å·å¢é•¿â€è®¡é¡µï¼‰
        """
        # ç›®æ ‡é¡µæ•°éšæœºåŒ–ï¼ˆæ›´åƒçœŸäººï¼‰
        if max_pages < min_pages:
            max_pages = min_pages
        target_pages = random.randint(min_pages, max_pages)

        logger.info(f"ç›®æ ‡ï¼šæµè§ˆè¯„è®º {target_pages} é¡µï¼ˆæ‰¹æ¬¡ï¼‰")

        # 1) ç¡®ä¿å›å¤æµ ready
        self.wait_topic_posts_ready(page, timeout=40)

        # 2) åƒäººåœé¡¿ä¸€ä¸‹
        time.sleep(random.uniform(1.5, 3.0))

        pages_done = 0
        last_post_no = self._current_post_number(page)
        if last_post_no:
            logger.info(f"åˆå§‹æ—¶é—´è½´æ¥¼å±‚å·: #{last_post_no}")
        else:
            logger.info("åˆå§‹æœªèƒ½è¯»å–æ¥¼å±‚å·ï¼ˆä»ç»§ç»­æµè§ˆï¼‰")

        # é˜²æ­¢æ­»å¾ªç¯ï¼šæœ€å¤šå°è¯•æ¬¡æ•°
        max_loops = target_pages * 6 + 12

        for i in range(max_loops):
            # åˆ†æ®µæ»šåŠ¨ï¼ˆæ›´åƒâ€œç¿»é¡µ/åˆ·è¯„è®ºâ€ï¼‰
            scroll_distance = random.randint(900, 1400)
            logger.info(f"[loop {i+1}] å‘ä¸‹æ»šåŠ¨ {scroll_distance}px æµè§ˆè¯„è®º...")
            page.run_js(f"window.scrollBy(0, {scroll_distance});")

            # å°ç­‰å¾…è®©å‰ç«¯è§¦å‘åŠ è½½
            time.sleep(random.uniform(0.8, 1.6))

            # å…³é”®ï¼šç­‰å³ä¾§æ—¶é—´è½´ç¨³å®šï¼ˆä½ è¯´çš„è“ç‚¹ä¸å†å˜åŒ–/åŠ è½½å®Œæˆï¼‰
            self.wait_topic_progress_stable(
                page,
                stable_seconds=random.uniform(2.0, 3.2),
                timeout=25
            )

            # è¯»å–å½“å‰æ¥¼å±‚å·
            cur_post_no = self._current_post_number(page)

            # åˆ¤æ–­æ˜¯å¦â€œç¿»åˆ°ä¸‹ä¸€é¡µ/æ‰¹æ¬¡â€
            if cur_post_no and last_post_no and cur_post_no > last_post_no:
                pages_done += 1
                logger.success(
                    f"âœ… å·²æµè§ˆç¬¬ {pages_done}/{target_pages} é¡µï¼ˆæ¥¼å±‚ #{last_post_no} -> #{cur_post_no}ï¼‰"
                )
                last_post_no = cur_post_no

                # ç¿»é¡µåå¤šåœç•™ï¼šåƒåœ¨è¯»è¿™ä¸€å±è¯„è®º
                time.sleep(random.uniform(3.5, 8.0))
            else:
                # æ²¡ç¿»é¡µä¹Ÿåœç•™ï¼šåƒåœ¨è¯»å·²åŠ è½½çš„è¯„è®º
                time.sleep(random.uniform(2.0, 5.0))

            if pages_done >= target_pages:
                logger.success("ğŸ‰ å·²è¾¾åˆ°ç›®æ ‡è¯„è®ºé¡µæ•°ï¼Œç»“æŸæµè§ˆ")
                return True

            # åˆ°åº•éƒ¨é€€å‡º
            try:
                at_bottom = page.run_js(
                    "return (window.scrollY + window.innerHeight) >= (document.body.scrollHeight - 5);"
                )
                if at_bottom:
                    logger.success("å·²åˆ°è¾¾é¡µé¢åº•éƒ¨ï¼Œç»“æŸæµè§ˆ")
                    return pages_done >= min_pages
            except Exception:
                pass

        logger.warning("è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°ä»æœªå®Œæˆç›®æ ‡é¡µæ•°ï¼ˆå¯èƒ½åŠ è½½æ…¢/ç»“æ„å˜åŒ–ï¼‰")
        return pages_done >= min_pages

    # ----------------------------
    # Browse from latest list
    # ----------------------------
    def click_topic(self):
        # ç¡®ä¿åœ¨åˆ—è¡¨é¡µ
        if not self.page.url.startswith("https://linux.do/latest"):
            self.page.get(LIST_URL)

        if not self._wait_any_topic_link(timeout=35):
            logger.error("æœªæ‰¾åˆ° a.raw-topic-linkï¼ˆä¸»é¢˜æ ‡é¢˜é“¾æ¥ï¼‰ï¼Œå¯èƒ½é¡µé¢æœªæ¸²æŸ“å®Œæˆæˆ–ç»“æ„å˜æ›´")
            logger.error(f"å½“å‰URL: {self.page.url}")
            logger.error((self.page.html or "")[:500])
            return False

        topic_links = self.page.eles("css:a.raw-topic-link")
        if not topic_links:
            logger.error("ä¸»é¢˜é“¾æ¥åˆ—è¡¨ä¸ºç©º")
            logger.error(f"å½“å‰URL: {self.page.url}")
            logger.error((self.page.html or "")[:500])
            return False

        logger.info(f"å‘ç° {len(topic_links)} ä¸ªä¸»é¢˜å¸–ï¼Œéšæœºé€‰æ‹©50ä¸ª")
        for a in random.sample(topic_links, min(50, len(topic_links))):
            href = a.attr("href")
            if not href:
                continue
            if href.startswith("/"):
                href = "https://linux.do" + href
            self.click_one_topic(href)

        return True

    @retry_decorator()
    def click_one_topic(self, topic_url):
        new_page = self.browser.new_tab()
        try:
            new_page.get(topic_url)

            # å…ˆç­‰å›å¤/è¯„è®ºæµ ready + æ—¶é—´è½´ç¨³å®š
            self.wait_topic_posts_ready(new_page, timeout=40)
            time.sleep(random.uniform(1.2, 2.5))
            self.wait_topic_progress_stable(new_page, stable_seconds=2.2, timeout=25)

            # ç‚¹èµï¼ˆå¯é€‰ï¼‰
            if random.random() < 0.3:
                self.click_like(new_page)

            # âœ… å…³é”®ï¼šè‡³å°‘æµè§ˆ 5~10 é¡µè¯„è®ºï¼ˆæŒ‰å³ä¾§æ¥¼å±‚å·å¢é•¿è®¡é¡µï¼‰
            ok = self.browse_replies_pages(
                new_page,
                min_pages=MIN_COMMENT_PAGES,
                max_pages=MAX_COMMENT_PAGES
            )
            if not ok:
                logger.warning("æœ¬ä¸»é¢˜æœªè¾¾åˆ°æœ€å°è¯„è®ºé¡µæ•°ç›®æ ‡ï¼ˆå¯èƒ½å¸–å­å¾ˆçŸ­/åˆ°åº•/åŠ è½½æ…¢ï¼‰")

        finally:
            try:
                new_page.close()
            except Exception:
                pass

    # ----------------------------
    # Like
    # ----------------------------
    def click_like(self, page):
        try:
            like_button = page.ele(".discourse-reactions-reaction-button")
            if like_button:
                logger.info("æ‰¾åˆ°æœªç‚¹èµçš„å¸–å­ï¼Œå‡†å¤‡ç‚¹èµ")
                like_button.click()
                logger.info("ç‚¹èµæˆåŠŸ")
                time.sleep(random.uniform(1, 2))
            else:
                logger.info("å¸–å­å¯èƒ½å·²ç»ç‚¹è¿‡èµäº†")
        except Exception as e:
            logger.error(f"ç‚¹èµå¤±è´¥: {str(e)}")

    # ----------------------------
    # Run
    # ----------------------------
    def run(self):
        try:
            login_res = self.login()
            if not login_res:
                logger.warning("ç™»å½•å¤±è´¥ï¼Œåç»­ä»»åŠ¡å¯èƒ½æ— æ³•è¿›è¡Œ")

            if BROWSE_ENABLED:
                click_topic_res = self.click_topic()
                if not click_topic_res:
                    logger.error("ç‚¹å‡»ä¸»é¢˜å¤±è´¥ï¼Œç¨‹åºç»ˆæ­¢")
                    return
                logger.info("å®Œæˆæµè§ˆä»»åŠ¡ï¼ˆå«è¯„è®ºæµè§ˆï¼‰")

            self.send_notifications(BROWSE_ENABLED)
        finally:
            try:
                self.page.close()
            except Exception:
                pass
            try:
                self.browser.quit()
            except Exception:
                pass

    # ----------------------------
    # Connect info
    # ----------------------------
    def print_connect_info(self):
        logger.info("è·å–è¿æ¥ä¿¡æ¯")
        headers = {
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        }
        resp = self.session.get(
            "https://connect.linux.do/",
            headers=headers,
            impersonate="chrome136",
            allow_redirects=True,
            timeout=30,
        )
        soup = BeautifulSoup(resp.text, "html.parser")
        rows = soup.select("table tr")
        info = []

        for row in rows:
            cells = row.select("td")
            if len(cells) >= 3:
                project = cells[0].text.strip()
                current = cells[1].text.strip() if cells[1].text.strip() else "0"
                requirement = cells[2].text.strip() if cells[2].text.strip() else "0"
                info.append([project, current, requirement])

        print("--------------Connect Info-----------------")
        print(tabulate(info, headers=["é¡¹ç›®", "å½“å‰", "è¦æ±‚"], tablefmt="pretty"))

    # ----------------------------
    # Notifications
    # ----------------------------
    def send_notifications(self, browse_enabled):
        status_msg = f"âœ…æ¯æ—¥ç™»å½•æˆåŠŸ: {USERNAME}"
        if browse_enabled:
            status_msg += f" + æµè§ˆä»»åŠ¡å®Œæˆ(å«è¯„è®º{MIN_COMMENT_PAGES}-{MAX_COMMENT_PAGES}é¡µ)"

        if GOTIFY_URL and GOTIFY_TOKEN:
            try:
                response = requests.post(
                    f"{GOTIFY_URL}/message",
                    params={"token": GOTIFY_TOKEN},
                    json={"title": "LINUX DO", "message": status_msg, "priority": 1},
                    timeout=10,
                )
                response.raise_for_status()
                logger.success("æ¶ˆæ¯å·²æ¨é€è‡³Gotify")
            except Exception as e:
                logger.error(f"Gotifyæ¨é€å¤±è´¥: {str(e)}")
        else:
            logger.info("æœªé…ç½®Gotifyç¯å¢ƒå˜é‡ï¼Œè·³è¿‡é€šçŸ¥å‘é€")

        if SC3_PUSH_KEY:
            match = re.match(r"sct(\d+)t", SC3_PUSH_KEY, re.I)
            if not match:
                logger.error("âŒ SC3_PUSH_KEYæ ¼å¼é”™è¯¯ï¼Œæœªè·å–åˆ°UIDï¼Œæ— æ³•ä½¿ç”¨Serveré…±Â³æ¨é€")
                return

            uid = match.group(1)
            url = f"https://{uid}.push.ft07.com/send/{SC3_PUSH_KEY}"
            params = {"title": "LINUX DO", "desp": status_msg}

            attempts = 5
            for attempt in range(attempts):
                try:
                    response = requests.get(url, params=params, timeout=10)
                    response.raise_for_status()
                    logger.success(f"Serveré…±Â³æ¨é€æˆåŠŸ: {response.text}")
                    break
                except Exception as e:
                    logger.error(f"Serveré…±Â³æ¨é€å¤±è´¥: {str(e)}")
                    if attempt < attempts - 1:
                        sleep_time = random.randint(180, 360)
                        logger.info(f"å°†åœ¨ {sleep_time} ç§’åé‡è¯•...")
                        time.sleep(sleep_time)

        if WXPUSH_URL and WXPUSH_TOKEN:
            try:
                response = requests.post(
                    f"{WXPUSH_URL}/wxsend",
                    headers={
                        "Authorization": WXPUSH_TOKEN,
                        "Content-Type": "application/json",
                    },
                    json={"title": "LINUX DO", "content": status_msg},
                    timeout=10,
                )
                response.raise_for_status()
                logger.success(f"wxpush æ¨é€æˆåŠŸ: {response.text}")
            except Exception as e:
                logger.error(f"wxpush æ¨é€å¤±è´¥: {str(e)}")
        else:
            logger.info("æœªé…ç½® WXPUSH_URL æˆ– WXPUSH_TOKENï¼Œè·³è¿‡é€šçŸ¥å‘é€")


if __name__ == "__main__":
    if not USERNAME or not PASSWORD:
        print("Please set LINUXDO_USERNAME/LINUXDO_PASSWORD (or USERNAME/PASSWORD)")
        raise SystemExit(1)

    l = LinuxDoBrowser()
    l.run()
